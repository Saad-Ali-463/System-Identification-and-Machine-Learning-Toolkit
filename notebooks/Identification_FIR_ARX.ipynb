{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PART 1: IDENTIFICATION (Python)\n",
        "FIR & ARX with Least Squares + MDL (mirrors the MATLAB-style workflow).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "from sysid.hankel import hankel_fir, hankel_arx\n",
        "from sysid.ls import ls_fit\n",
        "from sysid.metrics import mse_loss, mdl_score, nrmse\n",
        "from sysid.utils import autocorr, train_valid_split\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "df = pd.read_csv('../data/sample_timeseries.csv')\n",
        "u, y = df['u'].values, df['y'].values\n",
        "plt.figure(figsize=(10,3)); plt.plot(u[:200]); plt.title('Input u (first 200)'); plt.grid(True)\n",
        "plt.figure(figsize=(10,3)); plt.plot(y[:200]); plt.title('Output y (first 200)'); plt.grid(True)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "ac = autocorr(y, max_lag=30)\n",
        "plt.figure(); plt.stem(range(len(ac)), ac, use_line_collection=True)\n",
        "plt.title('AutoCorrelation of y'); plt.xlabel('Lag'); plt.ylabel('rho'); plt.grid(True)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "u_tr, y_tr, u_va, y_va = train_valid_split(u, y, 0.8)\n",
        "len(y_tr), len(y_va)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "max_order = 20\n",
        "loss_fir, mdl_fir = [], []\n",
        "for n in range(1, max_order+1):\n",
        "    Phi = hankel_fir(u_tr, n)\n",
        "    target = y_tr[n:]\n",
        "    theta, yhat = ls_fit(Phi, target)\n",
        "    J = mse_loss(target, yhat)\n",
        "    loss_fir.append(J)\n",
        "    mdl_fir.append(mdl_score(J, len(y_tr)-n, n))\n",
        "best_fir = int(np.argmin(mdl_fir)+1)\n",
        "best_fir\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "Phi_fir = hankel_fir(u_tr, best_fir)\n",
        "theta_fir, yhat_tr_fir = ls_fit(Phi_fir, y_tr[best_fir:])\n",
        "Phi_fir_v = hankel_fir(u_va, best_fir)\n",
        "yhat_va_fir = Phi_fir_v @ theta_fir\n",
        "nrmse_fir = nrmse(y_va[best_fir:], yhat_va_fir)\n",
        "nrmse_fir\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "loss_arx, mdl_arx = [], []\n",
        "for n in range(1, max_order+1):\n",
        "    Phi = hankel_arx(u_tr, y_tr, n)\n",
        "    target = y_tr[n:]\n",
        "    theta, yhat = ls_fit(Phi, target)\n",
        "    J = mse_loss(target, yhat)\n",
        "    loss_arx.append(J)\n",
        "    mdl_arx.append(mdl_score(J, len(y_tr)-n, 2*n))\n",
        "best_arx = int(np.argmin(mdl_arx)+1)\n",
        "best_arx\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Mark minimum MDL points for FIR & ARX (if arrays exist)\n",
        "import numpy as np\n",
        "min_idx_fir = int(np.argmin(mdl_fir)+1); min_val_fir = float(np.min(mdl_fir))\n",
        "plt.figure(); plt.plot(range(1, max_order+1), mdl_fir, '-o');\n",
        "plt.scatter([min_idx_fir],[min_val_fir]); plt.text(min_idx_fir, min_val_fir, f\" min MDL={min_idx_fir}\")\n",
        "plt.title('Order Estimation by MDL (FIR)'); plt.xlabel('order n'); plt.ylabel('MDL(n)'); plt.grid(True)\n",
        "\n",
        "min_idx_arx = int(np.argmin(mdl_arx)+1); min_val_arx = float(np.min(mdl_arx))\n",
        "plt.figure(); plt.plot(range(1, max_order+1), mdl_arx, '-o');\n",
        "plt.scatter([min_idx_arx],[min_val_arx]); plt.text(min_idx_arx, min_val_arx, f\" min MDL={min_idx_arx}\")\n",
        "plt.title('Order Estimation by MDL (ARX)'); plt.xlabel('order n'); plt.ylabel('MDL(n)'); plt.grid(True)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "Phi_arx = hankel_arx(u_tr, y_tr, best_arx)\n",
        "theta_arx, yhat_tr_arx = ls_fit(Phi_arx, y_tr[best_arx:])\n",
        "Phi_arx_v = hankel_arx(u_va, y_va, best_arx)\n",
        "yhat_va_arx = Phi_arx_v @ theta_arx\n",
        "nrmse_arx = nrmse(y_va[best_arx:], yhat_va_arx)\n",
        "nrmse_arx\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "k = range(len(y_va))\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(y_va, label='y_valid')\n",
        "plt.plot(list(k)[best_fir:], yhat_va_fir, label=f'FIR(n={best_fir})')\n",
        "plt.plot(list(k)[best_arx:], yhat_va_arx, label=f'ARX(n={best_arx})')\n",
        "plt.legend(); plt.grid(True); plt.title('Validation Fit')\n",
        "print('NRMSE - FIR:', nrmse_fir)\n",
        "print('NRMSE - ARX:', nrmse_arx)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Whiteness & Cross-correlation tests (ARX residuals)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "eps = y_va[best_arx:] - yhat_va_arx\n",
        "from sysid.utils import autocorr as _ac, crosscorr\n",
        "ac_eps = _ac(eps, max_lag=30)\n",
        "plt.figure(); plt.stem(range(len(ac_eps)), ac_eps, use_line_collection=True)\n",
        "plt.title('AUTOCORRELATION OF ERRORS'); plt.xlabel('Lag'); plt.ylabel('rho'); plt.ylim(-1,1); plt.grid(True)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "lags, cc = crosscorr(eps, u_va[best_arx:], max_lag=30)\n",
        "plt.figure(); plt.stem(lags, cc, use_line_collection=True)\n",
        "plt.title('Cross-correlation: residuals vs input (validation)'); plt.xlabel('lag'); plt.ylabel('R_eu(lag)'); plt.ylim(-0.5,0.5); plt.grid(True)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "k = range(len(y_va))\n",
        "plt.figure();\n",
        "plt.plot(list(k)[best_arx:], y_va[best_arx:], label='Y validation')\n",
        "plt.plot(list(k)[best_arx:], yhat_va_arx, label='Y predicted')\n",
        "plt.legend(); plt.grid(True); plt.title('Validation vs Predicted (ARX)')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PART 2: CLASSIFICATION \u2014 Logistic Regression with Newton's Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
        "from classify.newton_logreg import fit_ovr_newton, predict_proba_ovr\n",
        "dfc = pd.read_csv('../data/sample_classification.csv')\n",
        "X = dfc[['x1','x2']].values; y = dfc['y'].values.astype(int)\n",
        "m = len(y); ntr = int(0.8*m)\n",
        "Xtr, ytr = X[:ntr], y[:ntr]\n",
        "Xte, yte = X[ntr:], y[ntr:]\n",
        "plt.figure(); plt.scatter(Xtr[:,0], Xtr[:,1], c=ytr, marker='o'); plt.title('Original representation of data (train)'); plt.grid(True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train with Newton's Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "Phi_tr = np.hstack([np.ones((Xtr.shape[0],1)), Xtr])\n",
        "theta, histories, classes = fit_ovr_newton(Phi_tr, ytr, max_iter=40, lr=1.0)\n",
        "plt.figure(); plt.plot(range(1, len(histories[-1])+1), histories[-1], '-o');\n",
        "plt.title('Loss function J(theta) for one-vs-rest (one class)'); plt.xlabel('iteration'); plt.ylabel('loss'); plt.grid(True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validation & Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "Phi_te = np.hstack([np.ones((Xte.shape[0],1)), Xte])\n",
        "P_tr = predict_proba_ovr(Phi_tr, theta)\n",
        "P_te = predict_proba_ovr(Phi_te, theta)\n",
        "yhat_tr = P_tr.argmax(axis=1)\n",
        "yhat_te = P_te.argmax(axis=1)\n",
        "acc_tr = (yhat_tr==ytr).mean(); acc_te=(yhat_te==yte).mean()\n",
        "print('Training acc %:', round(acc_tr*100,2), ' Test acc %:', round(acc_te*100,2))\n",
        "plt.figure(); plt.scatter(Xte[:,0], Xte[:,1], c=yhat_te, marker='o'); plt.title(\"Predicted classes (test)\"); plt.grid(True)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "mis = yhat_te != yte\n",
        "plt.figure();\n",
        "plt.scatter(Xte[~mis,0], Xte[~mis,1], marker='o');\n",
        "plt.scatter(Xte[mis,0], Xte[mis,1], marker='x');\n",
        "plt.title(\"'o' correct, 'x' misclassified (test)\"); plt.grid(True)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}